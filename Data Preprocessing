#A) Handle Missing Values

#Strategy:

#Numerical columns → fill with median

#Categorical columns → fill with "Unknown"


from sklearn.impute import SimpleImputer

num_cols = X.select_dtypes(include=["int64", "float64"]).columns
cat_cols = X.select_dtypes(include=["object"]).columns

num_imputer = SimpleImputer(strategy="median")
cat_imputer = SimpleImputer(strategy="most_frequent")

X[num_cols] = num_imputer.fit_transform(X[num_cols])
X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])

# Apply same transformations to test data
test_df[num_cols] = num_imputer.transform(test_df[num_cols])
test_df[cat_cols] = cat_imputer.transform(test_df[cat_cols])



#B) Categorical Encoding (One-Hot Encoding)
X = pd.get_dummies(X, columns=cat_cols)
test_df = pd.get_dummies(test_df, columns=cat_cols)

# Align columns (important!)
X, test_df = X.align(test_df, join="left", axis=1, fill_value=0)




#C) Feature Scaling

Neural Networks perform much better with scaled data.
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()

X[num_cols] = scaler.fit_transform(X[num_cols])
test_df[num_cols] = scaler.transform(test_df[num_cols])




